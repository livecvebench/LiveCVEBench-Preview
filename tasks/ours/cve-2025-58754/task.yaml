instruction: |-
  This application is built on axios, a popular HTTP client library for Node.js. The library
  supports data: URIs as a convenience feature - instead of making an HTTP request, it can
  decode embedded data and return it as a response.

  The library provides configuration options `maxContentLength` and `maxBodyLength` to limit
  response sizes and prevent memory exhaustion from oversized responses. However, users are
  reporting that these limits don't work consistently.

  When processing data: URIs (e.g., "data:text/plain;base64,..."), the size limits appear to
  be completely ignored. Even with `maxContentLength: 100` set, the library accepts and
  decodes arbitrarily large data: URI payloads without any error. For regular HTTP requests,
  the limit works correctly - responses exceeding the limit are rejected with
  "maxContentLength size of N exceeded".

  Example reproduction:
  ```javascript
  const axios = require('axios');

  // Create ~1KB of base64 data
  const largeData = Buffer.alloc(1024, 'X').toString('base64');
  const dataUrl = `data:text/plain;base64,${largeData}`;

  // This should fail but doesn't - limit is ignored for data: URIs
  const response = await axios.get(dataUrl, { maxContentLength: 100 });
  console.log(response.status);  // Returns 200 instead of throwing error
  ```

  The expected behavior is that `maxContentLength` should apply consistently to all response
  types, including synthetic responses from data: URIs. When the decoded size exceeds the
  configured limit, the request should be rejected with the same error message used for HTTP
  responses: "maxContentLength size of N exceeded".

difficulty: medium
category: bug-fix
tags:
  - nodejs
  - http-client
  - memory-management
  - configuration
parser_name: pytest

run_tests_in_same_shell: false
