"""
Vulnerability tests for parseDataUri function.
These tests verify that the RegEx denial of service issue is fixed.
Should FAIL in vulnerable state, PASS in fixed state.
"""

import subprocess
import pytest
import os
import signal

# Maximum time allowed for any single function call (in seconds)
MAX_EXECUTION_TIME = 5

# Threshold for considering a response "fast" (in milliseconds)
FAST_RESPONSE_THRESHOLD_MS = 1000


def run_parse_data_uri_with_timeout(input_uri: str, timeout: int = MAX_EXECUTION_TIME) -> dict:
    """
    Run the parseDataUri function with the given input and return the result.
    Uses strict timeout to detect hanging.
    Uses temp file for large inputs to avoid OS argument length limits.
    """
    import json
    import tempfile

    # Write input to temp file to avoid command line length limits
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        json.dump(input_uri, f)
        temp_path = f.name

    js_code = f'''
const fs = require('fs');
const {{ parseDataUri }} = require('/app/frontend/src/metabase/lib/dom.js');
const input = JSON.parse(fs.readFileSync('{temp_path}', 'utf8'));
const start = Date.now();
let result;
try {{
    result = parseDataUri(input);
}} catch (e) {{
    result = {{"error": e.message}};
}}
const duration = Date.now() - start;
console.log(JSON.stringify({{result: result, duration_ms: duration}}));
'''

    try:
        result = subprocess.run(
            ['node', '-e', js_code],
            capture_output=True,
            text=True,
            timeout=timeout,
            cwd='/app'
        )
        if result.returncode != 0:
            return {"result": None, "duration_ms": 0, "error": result.stderr, "timed_out": False}

        return {**json.loads(result.stdout.strip()), "timed_out": False}
    except subprocess.TimeoutExpired:
        return {"result": None, "duration_ms": timeout * 1000, "timed_out": True}
    except Exception as e:
        return {"result": None, "duration_ms": 0, "error": str(e), "timed_out": False}
    finally:
        # Clean up temp file
        try:
            os.unlink(temp_path)
        except:
            pass


class TestReDoSVulnerability:
    """
    Tests to verify the ReDoS vulnerability is fixed.
    These tests use malicious input patterns that cause catastrophic backtracking
    in the vulnerable regex pattern.
    """

    def test_primary_redos_payload(self):
        """
        Primary ReDoS test with the documented attack payload.
        This payload causes exponential backtracking in the vulnerable regex.
        """
        # The attack payload: null byte + repeated (null byte, comma) pattern + newlines
        malicious = "data:\u0000" + "\u0000," * 100000 + "\n1\n"

        result = run_parse_data_uri_with_timeout(malicious)

        # Should NOT timeout - that indicates vulnerability
        assert not result.get("timed_out", False), (
            f"Function timed out after {MAX_EXECUTION_TIME}s - ReDoS vulnerability present! "
            "The regex pattern causes catastrophic backtracking."
        )

        # Should complete quickly
        duration = result.get("duration_ms", MAX_EXECUTION_TIME * 1000)
        assert duration < FAST_RESPONSE_THRESHOLD_MS, (
            f"Function took {duration}ms which is too slow. "
            f"Expected < {FAST_RESPONSE_THRESHOLD_MS}ms. "
            "The regex pattern may still have performance issues."
        )

        # Result should be null for invalid input
        assert result.get("result") is None, (
            f"Expected null result for malformed input, got: {result.get('result')}"
        )

    def test_redos_shorter_payload(self):
        """
        ReDoS test with shorter payload that still triggers backtracking.
        Even with fewer repetitions, vulnerable regex will be slow.
        """
        malicious = "data:\u0000" + "\u0000," * 50000 + "\n"

        result = run_parse_data_uri_with_timeout(malicious)

        assert not result.get("timed_out", False), (
            "Function timed out - ReDoS vulnerability present!"
        )
        assert result.get("duration_ms", MAX_EXECUTION_TIME * 1000) < FAST_RESPONSE_THRESHOLD_MS, (
            f"Function took {result.get('duration_ms')}ms - too slow"
        )

    def test_redos_comma_only_pattern(self):
        """
        Test with repeated null-comma pattern ending with newline - triggers backtracking.
        """
        malicious = "data:" + "\u0000," * 50000 + "\n"

        result = run_parse_data_uri_with_timeout(malicious)

        assert not result.get("timed_out", False), (
            "Function timed out on comma pattern - ReDoS vulnerability present!"
        )
        assert result.get("duration_ms", MAX_EXECUTION_TIME * 1000) < FAST_RESPONSE_THRESHOLD_MS

    def test_redos_semicolon_pattern(self):
        """
        Test with null-comma pattern after semicolon data ending with newline.
        """
        malicious = "data:x;" + "\u0000," * 50000 + "\n"

        result = run_parse_data_uri_with_timeout(malicious)

        assert not result.get("timed_out", False), (
            "Function timed out on semicolon pattern - ReDoS vulnerability present!"
        )
        assert result.get("duration_ms", MAX_EXECUTION_TIME * 1000) < FAST_RESPONSE_THRESHOLD_MS

    def test_redos_mixed_special_chars(self):
        """
        Test with mixed special characters that create regex ambiguity.
        """
        malicious = "data:\u0000" + "\u0000\u0001," * 40000 + "\n"

        result = run_parse_data_uri_with_timeout(malicious)

        assert not result.get("timed_out", False), (
            "Function timed out on mixed pattern - ReDoS vulnerability present!"
        )
        assert result.get("duration_ms", MAX_EXECUTION_TIME * 1000) < FAST_RESPONSE_THRESHOLD_MS

    def test_redos_varying_lengths(self):
        """
        Test multiple payload lengths to ensure consistent performance.
        Vulnerable regex shows exponential slowdown with increasing length.
        """
        test_lengths = [10000, 25000, 50000]

        for length in test_lengths:
            malicious = "data:\u0000" + "\u0000," * length + "\n1\n"
            result = run_parse_data_uri_with_timeout(malicious)

            assert not result.get("timed_out", False), (
                f"Function timed out at length {length} - ReDoS vulnerability present!"
            )
            assert result.get("duration_ms", MAX_EXECUTION_TIME * 1000) < FAST_RESPONSE_THRESHOLD_MS, (
                f"Function too slow at length {length}: {result.get('duration_ms')}ms"
            )

    def test_redos_newline_variations(self):
        """
        Test with various newline patterns that prevent clean regex match.
        """
        payloads = [
            "data:\u0000" + "\u0000," * 50000 + "\n",
            "data:\u0000" + "\u0000," * 50000 + "\r\n",
            "data:\u0000" + "\u0000," * 50000 + "\n\n",
        ]

        for i, malicious in enumerate(payloads):
            result = run_parse_data_uri_with_timeout(malicious)

            assert not result.get("timed_out", False), (
                f"Function timed out on newline variant {i} - ReDoS vulnerability present!"
            )
            assert result.get("duration_ms", MAX_EXECUTION_TIME * 1000) < FAST_RESPONSE_THRESHOLD_MS

    def test_redos_with_base64_marker(self):
        """
        Test malicious input that includes base64 marker to exercise more regex paths.
        """
        malicious = "data:text/plain;base64," + "\u0000," * 50000 + "\n"

        result = run_parse_data_uri_with_timeout(malicious)

        assert not result.get("timed_out", False), (
            "Function timed out with base64 marker - ReDoS vulnerability present!"
        )
        assert result.get("duration_ms", MAX_EXECUTION_TIME * 1000) < FAST_RESPONSE_THRESHOLD_MS

class TestEdgeCasePerformance:
    """
    Additional ReDoS edge case tests.
    """

    def test_unicode_heavy_input(self):
        """Test with heavy unicode content that triggers regex backtracking."""
        # Mix of unicode characters ending with newline to trigger ReDoS
        malicious = "data:" + "\u0000\u0001," * 40000 + "\n"

        result = run_parse_data_uri_with_timeout(malicious)

        assert not result.get("timed_out", False), (
            "Function timed out on unicode pattern - potential ReDoS!"
        )
        assert result.get("duration_ms", MAX_EXECUTION_TIME * 1000) < FAST_RESPONSE_THRESHOLD_MS
