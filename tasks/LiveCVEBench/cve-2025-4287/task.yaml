instruction: |-
  This application uses PyTorch's NCCL (NVIDIA Collective Communications Library)
  bindings to perform distributed GPU operations like reduce, all_reduce, and
  reduce_scatter.

  When an invalid operation type parameter is passed to any of these NCCL
  functions (e.g., an integer value like 255 instead of the expected SUM constant
  which is 0), the entire process crashes with "Aborted (core dumped)" instead
  of raising a catchable Python exception.

  Example crash scenario:
  ```python
  from torch.cuda.nccl import reduce
  input_tensor = torch.tensor([1.0, 2.0, 3.0], device='cuda:0')
  output_tensor = torch.zeros_like(input_tensor)
  reduce(inputs=[input_tensor], output=output_tensor, root=0, op=255)
  # Result: "Aborted (core dumped)" - process terminates, no exception raised
  ```

  The affected functions are:
  - reduce()
  - all_reduce()
  - reduce_scatter()

  All three accept an `op` parameter but do not validate it before passing to
  the underlying C++ NCCL library, which aborts on invalid values.

  We expect these functions to validate the operation parameter and raise a
  proper Python exception (e.g., ValueError) for invalid values, rather than
  crashing the entire process.

author_name: HIT-SCIR-LACG
author_email: xzluo@ir.hit.edu.cn

difficulty: medium
category: bug-fix
tags:
  - python
  - input-validation
  - pytorch
  - cuda
parser_name: pytest

run_tests_in_same_shell: false
