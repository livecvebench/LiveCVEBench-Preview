#!/bin/bash
# Solution script for fixing event loop blocking during file upload rollover
#
# The vulnerability is in starlette/datastructures.py in the UploadFile class.
# When a file upload exceeds the SpooledTemporaryFile threshold (1MB), the
# rollover from memory to disk happens synchronously on the event loop thread,
# blocking all async operations.
#
# The fix:
# 1. Add _max_mem_size attribute to capture the spool threshold
# 2. Add _will_roll() method to predict if a write will trigger rollover
# 3. Modify write() to offload writes that will trigger rollover to a threadpool

set -e
cd /app

# Find the starlette package path dynamically (it's installed via pip, not in /app)
STARLETTE_PATH=$(python3 -c "import starlette; import os; print(os.path.dirname(starlette.__file__))")
DATASTRUCTURES_FILE="${STARLETTE_PATH}/datastructures.py"

echo "Found starlette at: $STARLETTE_PATH"
echo "Patching file: $DATASTRUCTURES_FILE"

# Check if file exists
if [ ! -f "$DATASTRUCTURES_FILE" ]; then
    echo "Error: $DATASTRUCTURES_FILE not found"
    exit 1
fi

# Create backup
cp "$DATASTRUCTURES_FILE" "${DATASTRUCTURES_FILE}.bak"

# Apply the fix using Python to handle the complex class modification
python3 << 'PYTHON_SCRIPT'
import re
import starlette
import os

# Find the actual path to datastructures.py
starlette_path = os.path.dirname(starlette.__file__)
datastructures_file = os.path.join(starlette_path, "datastructures.py")

print(f"Patching: {datastructures_file}")

with open(datastructures_file, "r") as f:
    content = f.read()

# Find and replace the UploadFile class
# The vulnerable code pattern in __init__:
old_init = '''    def __init__(
        self,
        file: BinaryIO,
        *,
        size: int | None = None,
        filename: str | None = None,
        headers: Headers | None = None,
    ) -> None:
        self.filename = filename
        self.file = file
        self.size = size
        self.headers = headers or Headers()'''

new_init = '''    def __init__(
        self,
        file: BinaryIO,
        *,
        size: int | None = None,
        filename: str | None = None,
        headers: Headers | None = None,
    ) -> None:
        self.filename = filename
        self.file = file
        self.size = size
        self.headers = headers or Headers()

        # Capture max size from SpooledTemporaryFile if one is provided. This slightly speeds up future checks.
        # Note 0 means unlimited mirroring SpooledTemporaryFile's __init__
        self._max_mem_size = getattr(self.file, "_max_size", 0)'''

if old_init in content:
    content = content.replace(old_init, new_init)
    print("Applied fix to __init__ method")
else:
    # Check if already fixed
    if "_max_mem_size" in content:
        print("__init__ appears to be already fixed")
    else:
        print("Warning: Could not find __init__ pattern to patch")

# Add _will_roll method after _in_memory property
old_in_memory = '''    @property
    def _in_memory(self) -> bool:
        # check for SpooledTemporaryFile._rolled
        rolled_to_disk = getattr(self.file, "_rolled", True)
        return not rolled_to_disk

    async def write'''

new_in_memory = '''    @property
    def _in_memory(self) -> bool:
        # check for SpooledTemporaryFile._rolled
        rolled_to_disk = getattr(self.file, "_rolled", True)
        return not rolled_to_disk

    def _will_roll(self, size_to_add: int) -> bool:
        # If we're not in_memory then we will always roll
        if not self._in_memory:
            return True

        # Check for SpooledTemporaryFile._max_size
        future_size = self.file.tell() + size_to_add
        return bool(future_size > self._max_mem_size) if self._max_mem_size else False

    async def write'''

if old_in_memory in content:
    content = content.replace(old_in_memory, new_in_memory)
    print("Added _will_roll method")
else:
    if "_will_roll" in content:
        print("_will_roll method appears to already exist")
    else:
        print("Warning: Could not find location to add _will_roll method")

# Fix the write method
old_write = '''    async def write(self, data: bytes) -> None:
        if self.size is not None:
            self.size += len(data)

        if self._in_memory:
            self.file.write(data)
        else:
            await run_in_threadpool(self.file.write, data)'''

new_write = '''    async def write(self, data: bytes) -> None:
        new_data_len = len(data)
        if self.size is not None:
            self.size += new_data_len

        if self._will_roll(new_data_len):
            await run_in_threadpool(self.file.write, data)
        else:
            self.file.write(data)'''

if old_write in content:
    content = content.replace(old_write, new_write)
    print("Fixed write method")
else:
    if "_will_roll(new_data_len)" in content:
        print("write method appears to be already fixed")
    else:
        print("Warning: Could not find write method pattern to patch")

with open(datastructures_file, "w") as f:
    f.write(content)

print("Fix applied successfully")
PYTHON_SCRIPT

echo "Solution applied to $DATASTRUCTURES_FILE"
