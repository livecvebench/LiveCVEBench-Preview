# LiveCVEBench (Preview) üõ°Ô∏è

**A Contamination-Free Agentic Benchmark for Evaluating Code Agents on Real-World CVE Vulnerability Fixing.**

[![Leaderboard](https://img.shields.io/badge/üèÜ-Leaderboard-gold?style=for-the-badge)](https://livecvebench.github.io/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Preview-orange)](https://github.com/livecvebench/LiveCVEBench-Preview)

---

## üåü Introduction

**LiveCVEBench** presents a preview version of a cutting-edge benchmark designed to evaluate the capabilities of AI Code Agents in fixing real-world security vulnerabilities (CVEs). Unlike traditional benchmarks, LiveCVEBench focuses on "contamination-free" evaluation by incorporating the most recent vulnerabilities and providing a realistic, terminal-based interaction environment.

For the latest rankings and results, visit our **[Official Leaderboard](https://livecvebench.github.io/)**.

---

## üìÇ Dataset Structure

The benchmark tasks are located in the `tasks/` directory, categorized by their source and format:

### 1. `tasks/ours/`
*   **Description**: Contains **new CVEs from 2025** generated by our team.
*   **Format**: These tasks rely strictly on **User Reports**. This simulates real-world scenarios where an agent must reproduce and fix a bug based on a user's description of the issue, without being given the exact code location.

### 2. `tasks/patcheval/`
*   **Description**: A conversion of a subset of [PatchEval](https://github.com/bytedance/PatchEval) tasks (from the 2023-2025 timeframe) into the [Terminal Bench](https://www.tbench.ai/) format.
*   **Variants**:
    *   **`user-report/`**: Represents the actual problem scenario based on user reporting.
    *   **`cve-description/`**: Contains the original `patcheval` input, which often includes precise CVE descriptions and code localization. *Note: Both variants are evaluated in leaderboard.*

---

## üöÄ Quick Start: Evaluation

To facilitate usage, LiveCVEBench can be launched with one click using [Terminal Bench](https://www.tbench.ai/).

### Prerequisites
Ensure you have `uv` installed, then install the `terminal-bench` package (only supports version 1.0):

```bash
uv tool install terminal-bench@1.0
```

### Running the Evaluation
Execute the following command in the root of the repository. You can point to the exact sub-folder. (e.g., `tasks/ours` or `tasks/patcheval/user-report`).

```bash
tb run --dataset-path tasks/ours
```

---

## üõ†Ô∏è Task Generation Pipeline

Our task generation process ensures high-quality, reproducible CVE environments.

1.  **Sampler**: Select candidate CVEs (e.g., `CVE-xxx-xxx.md`) using `cve-sampler`. Please refer to [`cve-sampler/README.md`](cve-sampler/README.md) for detailed instructions on selection criteria.
2.  **Factory**:
    *   Clone the factory repo: `git clone https://github.com/livecvebench/CVE-Factory`
    *   Copy the selected `CVE-xxx-xxx.md` to `CVE-Factory/original_cves_md/`.
    *   Follow the instructions in `CVE-Factory/README.md` to generate the initial `cve_tasks`.
3.  **Conversion**: Convert the generated Docker environments into the `terminal-bench` format using the guide below.

---

## üìñ Migration Guide: Adapting CVEs to Terminal-Bench

This guide details how to migrate existing CVE environments (`Dockerfile` & `docker-compose.yaml`) into the Terminal-Bench (`tb`) framework.

### 1. Dockerfile Modifications

Ensure the Docker image has the necessary toolchain for the agent to operate.

**A. Check Mandatory Dependencies**
The following tools must be present: `tmux`, `asciinema`, `gcc`, `g++`, `wget`, `curl`, `git`.

```dockerfile
# Add this if missing
RUN apt-get update && apt-get install -y \
    tmux asciinema gcc g++ wget curl git
```

**B. Handle Entrypoints**
*   **Move** the `ENTRYPOINT` or `CMD` instruction from the Dockerfile to the `command` field in `docker-compose.yaml`.

---

### 2. `docker-compose.yaml` Standards

The `tb` framework requires a standardized service structure.

#### Core Template
```yaml
services:
  client:
    build:
      dockerfile: Dockerfile
    image: ${T_BENCH_TASK_DOCKER_CLIENT_IMAGE_NAME}
    container_name: ${T_BENCH_TASK_DOCKER_CLIENT_CONTAINER_NAME}
    command: [ "sh", "-c", "sleep infinity" ]  # Default or migrated start command
    environment:
      - TEST_DIR=${T_BENCH_TEST_DIR}
    volumes:
      - ${T_BENCH_TASK_LOGS_PATH}:${T_BENCH_CONTAINER_LOGS_PATH}
      - ${T_BENCH_TASK_AGENT_LOGS_PATH}:${T_BENCH_CONTAINER_AGENT_LOGS_PATH}
```

#### ‚ö†Ô∏è Critical Rules
1.  **Environment Variables**: All environment variables should go under `environment`.
2.  **No Ports**: **REMOVE** all `ports` mappings. Since all task execution happens *inside* the container, exposing ports to the host is unnecessary and causes conflicts during parallel execution. Ensure the task logic does not depend on external port access.
3.  **Healthchecks**: Similar to other settings, simple `healthcheck` configurations can be directly migrated from the original file.
4.  **Multi-Container Naming**: If using multiple containers, update secondary container names to be synchronized with the primary `client` container (using the same prefix variables) to avoid naming collisions during parallel runs.

---

### 3. Migration Examples

#### Case 1: Single Container (e.g., logseq)

**Before:**
```yaml
services:
  app:
    container_name: logseq-marketplace-app
    ports:
      - "8080:8080"
    CMD: ["/entrypoint.sh"]
```

**After (TB Adapted):**
```yaml
services:
  client:
    build:
      dockerfile: Dockerfile
    image: ${T_BENCH_TASK_DOCKER_CLIENT_IMAGE_NAME}
    container_name: ${T_BENCH_TASK_DOCKER_CLIENT_CONTAINER_NAME}
    command: ["/entrypoint.sh"]  # Moved from Dockerfile/CMD
    # ports: ["8080:8080"]       # REMOVED
    environment:
      - TEST_DIR=${T_BENCH_TEST_DIR}
    volumes:
      - ${T_BENCH_TASK_LOGS_PATH}:${T_BENCH_CONTAINER_LOGS_PATH}
      - ${T_BENCH_TASK_AGENT_LOGS_PATH}:${T_BENCH_CONTAINER_AGENT_LOGS_PATH}
    healthcheck:
      # ... (Preserved)
```

#### Case 2: Multi-Container (e.g., ChurchCRM)

**Core Logic:**
1.   Rename main service to `client`.
2.   Add `${T_BENCH_...}` prefixes to image/container names.
3.   Prefix secondary container names with `${T_BENCH_TASK_DOCKER_CLIENT_CONTAINER_NAME}-`.

**After (TB Adapted):**
```yaml
services:
  client:
    # ... standard build/image configs ...
    container_name: ${T_BENCH_TASK_DOCKER_CLIENT_CONTAINER_NAME}
    environment:
      - TEST_DIR=${T_BENCH_TEST_DIR}
      - DB_HOST=database
      # ... other env vars
    depends_on:
      database:
        condition: service_healthy

  database:
    image: mariadb:10.6
    # PREFIX ADDED TO PREVENT CONFLICTS
    container_name: ${T_BENCH_TASK_DOCKER_CLIENT_CONTAINER_NAME}-churchcrm-cve-2025-11529-db
    environment:
      # ... db env vars
```

#### Case 3: Complex Multi-Container (e.g., Maho)

When dealing with 3+ containers (App, Database, Nginx), apply the prefix strategy consistently.

**After (TB Adapted):**
```yaml
services:
  client:
    # Main application logic
    container_name: ${T_BENCH_TASK_DOCKER_CLIENT_CONTAINER_NAME}
    environment:
      - TEST_DIR=${T_BENCH_TEST_DIR}
      - DB_HOST=db
      # ...
    depends_on:
      db: { condition: service_healthy }

  nginx:
    # Secondary service 1
    container_name: ${T_BENCH_TASK_DOCKER_CLIENT_CONTAINER_NAME}-maho-ecommerce-nginx
    depends_on:
      - client # was php

  db:
    # Secondary service 2
    container_name: ${T_BENCH_TASK_DOCKER_CLIENT_CONTAINER_NAME}-maho-ecommerce-db
```

---

## ü§ù Contributing

We are continuously expanding and updating this project. If you have any suggestions or would like to join/contribute to this project, please contact **xzluo@ir.hit.edu.cn**!

## ‚ö° Acknowledgements

We explicitly acknowledge the contributions of the following projects:
*   [PatchEval](https://github.com/bytedance/PatchEval)
*   [Terminal Bench](https://www.tbench.ai/)

## üñäÔ∏è Citation

If you find this benchmark useful, please cite:

```bibtex
@software{livecvebench,
  title = {LiveCVEBench: A Contamination-Free Agentic Benchmark for Evaluating Code Agents on Real-World CVE Vulnerability Fixing},
  year = {2025},
  url = {https://github.com/livecvebench/LiveCVEBench-Preview}
}
```

---
*Kuaishou Klear Team x HIT-SCIR-LACG*
