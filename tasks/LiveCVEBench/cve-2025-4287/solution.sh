#!/bin/bash
set -e

echo "=== Applying fix to PyTorch NCCL module ==="

# Find the torch installation path dynamically
TORCH_PATH=$(python -c "import torch; import os; print(os.path.dirname(torch.__file__))")
NCCL_FILE="$TORCH_PATH/cuda/nccl.py"

echo "Found torch at: $TORCH_PATH"
echo "Modifying: $NCCL_FILE"

# Verify file exists
if [ ! -f "$NCCL_FILE" ]; then
    echo "ERROR: nccl.py not found at $NCCL_FILE"
    exit 1
fi

# Create backup
cp "$NCCL_FILE" "$NCCL_FILE.bak"

# Apply the fix using Python for precision
python << 'PYEOF'
import os
import sys

torch_path = sys.argv[1] if len(sys.argv) > 1 else os.popen('python -c "import torch; import os; print(os.path.dirname(torch.__file__))"').read().strip()
nccl_file = os.path.join(torch_path, 'cuda', 'nccl.py')

with open(nccl_file, 'r') as f:
    content = f.read()

# Check if already fixed
if '_check_op_type' in content:
    print("Fix already applied, skipping")
    sys.exit(0)

# 1. Fix imports: change "from typing import Optional, Sequence, Union" to split version
content = content.replace(
    'from typing import Optional, Sequence, Union',
    'from collections.abc import Sequence\nfrom typing import Optional, Union'
)

# 2. Fix imports: change "import torch.cuda" to "import torch"
content = content.replace('import torch.cuda\n', 'import torch\n')

# 3. Add VALID_OPS constant after SUM definition
# Replace the SUM line with updated comment and VALID_OPS
old_sum_line = 'SUM = 0  # ncclRedOp_t'
new_sum_block = '''
# ncclRedOp_t
SUM = 0  # ncclSum

VALID_OPS = {SUM}
'''
content = content.replace(old_sum_line, new_sum_block.strip())

# 4. Add _check_op_type function after _check_sequence_type function
check_op_type_func = '''

def _check_op_type(op: int):
    if not isinstance(op, int):
        raise TypeError(f"Expected op type int, got {type(op).__name__}")
    if op not in VALID_OPS:
        raise ValueError(
            f"Invalid op: {op}. Valid options are {', '.join(map(str, VALID_OPS))}"
        )

'''

# Find the end of _check_sequence_type function and insert after it
import re

# Find _check_sequence_type function and insert _check_op_type after it
pattern = r'(def _check_sequence_type\([^)]*\)[^:]*:.*?raise TypeError\("Inputs should be a collection of tensors"\))'
match = re.search(pattern, content, re.DOTALL)
if match:
    end_pos = match.end()
    content = content[:end_pos] + check_op_type_func + content[end_pos:]

# 5. Add _check_op_type(op) call in all_reduce function
# Find all_reduce and add _check_op_type(op) as first line after function def
content = re.sub(
    r'(def all_reduce\(inputs, outputs=None, op=SUM, streams=None, comms=None\):)\n(\s+)(_check_sequence_type\(inputs\))',
    r'\1\n\2_check_op_type(op)\n\2\3',
    content
)

# 6. Add _check_op_type(op) call in reduce function
# Find the reduce function and add _check_op_type(op) before _check_sequence_type(inputs)
content = re.sub(
    r'(def reduce\(\s*\n\s+inputs: Sequence\[torch\.Tensor\],\s*\n\s+output: Optional\[Union\[torch\.Tensor, Sequence\[torch\.Tensor\]\]\] = None,\s*\n\s+root: int = 0,\s*\n\s+op: int = SUM,\s*\n\s+streams: Optional\[Sequence\[torch\.cuda\.Stream\]\] = None,\s*\n\s+comms=None,\s*\n\s+\*,\s*\n\s+outputs: Optional\[Sequence\[torch\.Tensor\]\] = None,\s*\n\) -> None:)\n(\s+)(_check_sequence_type\(inputs\))',
    r'\1\n\2_check_op_type(op)\n\2\3',
    content
)

# 7. Add _check_op_type(op) call in reduce_scatter function
content = re.sub(
    r'(def reduce_scatter\(\s*\n\s+inputs: Sequence\[torch\.Tensor\],\s*\n\s+outputs: Sequence\[torch\.Tensor\],\s*\n\s+op: int = SUM,\s*\n\s+streams=None,\s*\n\s+comms=None,\s*\n\) -> None:)\n(\s+)(_check_sequence_type\(inputs\))',
    r'\1\n\2_check_op_type(op)\n\2\3',
    content
)

# Write the fixed content
with open(nccl_file, 'w') as f:
    f.write(content)

print("Fix applied successfully")
PYEOF

# Verify the fix was applied
echo ""
echo "=== Verifying fix ==="
python -c "
import torch
import os

torch_path = os.path.dirname(torch.__file__)
nccl_file = os.path.join(torch_path, 'cuda', 'nccl.py')

with open(nccl_file, 'r') as f:
    content = f.read()

if '_check_op_type' in content:
    print('SUCCESS: _check_op_type function found')
else:
    print('WARNING: _check_op_type function not found')
    exit(1)

if 'VALID_OPS' in content:
    print('SUCCESS: VALID_OPS constant found')
else:
    print('WARNING: VALID_OPS constant not found')
    exit(1)

# Test that the fix works
from torch.cuda.nccl import reduce, all_reduce, reduce_scatter

# These should raise ValueError for invalid ops
try:
    # Dummy test - will fail on type check before reaching CUDA
    import torch.cuda.nccl as nccl
    if hasattr(nccl, '_check_op_type'):
        print('SUCCESS: _check_op_type is accessible')
except Exception as e:
    print(f'Note: {e}')

print('Fix verification complete')
"

echo ""
echo "=== Fix applied successfully ==="
